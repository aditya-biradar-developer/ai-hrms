# AI Service Configuration
PORT=5001
FLASK_ENV=development

# ðŸš€ GROQ AI Configuration
# Get your free API key: https://console.groq.com/
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-70b-versatile

# ðŸŒŸ Google Gemini AI Configuration
# Get your free API key: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# ðŸš€ HuggingFace Inference API
# Get free API key: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# LLM Configuration
# Set to 'true' to use Ollama (recommended), 'false' to use llama-cpp-python
USE_OLLAMA=true

# Ollama Configuration
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama2:7b-chat

# llama-cpp-python Configuration
MODEL_PATH=./models/llama-2-7b-chat.gguf

# Generation Parameters
MAX_TOKENS=2048
TEMPERATURE=0.7
TOP_P=0.95

# API Configuration
BACKEND_URL=http://localhost:5000
API_SECRET=your_generated_api_secret_here

# Vector Store
CHROMA_DB_PATH=./data/chroma_db
